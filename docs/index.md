---
layout: default
---

In the past decade, data-driven analysis has emerged as a growing methodology, if not sub-discipline within literary studies. This approach, broadly described as “_distant reading_”, has harnessed available technology to open new avenues for how we understand literary texts, both individually and in the aggregate. Whereas traditional literary scholarship is generally grounded in the interpretation of the specific language of a text or body of texts, macroanalytic approaches have offered new ways of seeing texts. Rather than generating claims based upon the interpretation of a handful of novels, distant reading offers the opportunity to work with hundreds, if not thousands, of texts; this has led to analyses, for example, of the nature of and changes within semantic fields across the span of decades, or the identification of generic markers within large corpora of texts. However, while computational analysis provides the opportunity to pursue previously unimaginable questions, scholars are still in the early stages of establishing the significance and meaning of such approaches, particularly in relation to the inherited body of scholarship that defines the discipline. What, in other words, do the graphs, charts, and maps generated by data-driven analysis tell us about literature, and about what an individual text might mean? Thus, in addition to pursuing new questions and applying new methods in the computational analysis of literary texts, there is a continuing need to theorise the relationship between macroanalytic and microanalytic (distant and close) readings of individual works.

This project brings together researchers from computer science and literary studies to develop and evaluate novel distant reading approaches.

# [](#header-1)Project outcome I: Creating Transcendental Information Cascades from English Literature

# [](#header-1)Team
